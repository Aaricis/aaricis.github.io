---
title: LangChain for LLM Application Development
date: 2024-12-05 16:40:00 +/-8
categories: [LLM, Andrew Ng]
tags: [openai, software develop, langchain]     # TAG names should always be lowercase
---

æœ¬è¯¾ç¨‹æ˜¯å´æ©è¾¾ä¸OpenAIã€Hugging Faceã€LangChainç­‰æœºæ„è”åˆæ‰“é€ ï¼Œé¢å‘å¼€å‘è€…çš„LLMç³»åˆ—è¯¾ç¨‹ç¬¬ä¸‰è®²â€”â€”ç”¨äºLLMåº”ç”¨ç¨‹åºå¼€å‘çš„LangChainï¼Œç”±LangChainè”åˆåˆ›å§‹äººå…¼CEO Harrison Chaseå’Œå´æ©è¾¾åˆä½œæˆè¯¾ã€‚

## è¯¾ç¨‹é“¾æ¥

[LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)

>å»ºè®®å¤§å®¶ç›´æ¥çœ‹DeepLearning.AIä¸Šçš„è‹±æ–‡åŸç‰ˆï¼Œé…åˆå®˜æ–¹æä¾›çš„Jupyter Notebookæ•ˆæœæ›´ä½³ã€‚Bç«™ä¸Šçš„ç¿»è¯‘ç¨€çƒ‚ï¼Œä¸å»ºè®®çœ‹ï¼Œå¯èƒ½ä¼šé€ æˆè¯¯å¯¼ã€‚
>

## æ¦‚è¿°

åŸºäºLLM APIå¼€å‘åº”ç”¨ç¨‹åºä¹‹å‰ï¼Œå¼€å‘è€…ä¸å¾—ä¸å†™å¾ˆå¤šèƒ¶æ°´ä»£ç æ‰èƒ½æ­å»ºå®Œæ•´çš„ç¨‹åºæ¡†æ¶ã€‚LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘åŸºäºLLMçš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ï¼Œå®ƒç®€åŒ–äº†LLMåº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼ŒåŒ…æ‹¬å¼€å‘ã€éƒ¨ç½²å’Œäº§å“åŒ–ï¼Œå·²ç»è¢«å¹¿å¤§å¼€å‘è€…ã€åˆåˆ›å…¬å¸å’Œå¤§å‹ä¼ä¸šå¹¿æ³›ä½¿ç”¨ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¹¶ä½¿ç”¨LangChainå¼€å‘å®Œæ•´å¥å£®çš„åº”ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š

- Models, Prompts and Parsersï¼šè°ƒç”¨LLMï¼Œæä¾›promptï¼Œè§£æresponseï¼›
- Memories for LLMsï¼šå­˜å‚¨å¯¹è¯å’Œç®¡ç†æœ‰é™ä¸Šä¸‹æ–‡ç©ºé—´ï¼›
- Chainsï¼šåˆ›å»ºæ“ä½œåºåˆ—ï¼›
- Question Answering over Documentsï¼šå°†LLMåº”ç”¨åˆ°ä¸“æœ‰æ•°æ®å’Œç”¨ä¾‹ï¼›
- Agentsï¼šæ¢ç´¢LLMä½œä¸ºæ¨ç†ä»£ç†çš„å¼ºå¤§æ–°å…´å‘å±•ã€‚

## Introduction

ä¸ºäº†ç®€åŒ–åŸºäºLLMçš„AIåº”ç”¨ç¨‹åºå¼€å‘ï¼ŒHarrison Chaseåˆ›é€ äº†LangChainã€‚LangChainæ˜¯å¼€å‘æ¡†æ¶ä¹Ÿæ˜¯æ´»è·ƒçš„å¼€æºç¤¾åŒºï¼Œæœ‰æ•°ç™¾åè´¡çŒ®è€…ï¼Œæ­£ä»¥æƒŠäººçš„é€Ÿåº¦è¿­ä»£æ–°åŠŸèƒ½ã€‚LangChainæä¾›Pythonå’ŒJavaScriptä¸¤ç§åŒ…ï¼Œä¸“æ³¨äºç»„åˆå’Œæ¨¡å—åŒ–ï¼Œå¯ä»¥è½»æ¾çš„å°†å„ä¸ªç»„ä»¶ç»“åˆèµ·æ¥åˆ›å»ºç«¯åˆ°ç«¯åº”ç”¨ç¨‹åºã€‚

æœ¬è¯¾ç¨‹é‡ç‚¹ä»‹ç»LangChainçš„å¸¸ç”¨ç»„ä»¶ï¼šModels, Prompts, Indexes, Chains, Agentsã€‚

![](../assets/images/llm_develop/langchain-1.png)

## Models, Prompts and Parsers

### Chat API : LangChain

å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„`langchain`åŒ…

```python
pip install --upgrade langchain
```

### Model

ä»`langchain.chat_models`å¯¼å…¥OpenAIå¯¹è¯æ¨¡å‹ã€‚LangChainä¹Ÿé›†æˆäº†å…¶ä»–å‚å•†çš„æ¨¡å‹ï¼Œå¦‚Anthropicã€Googleç­‰ï¼Œå‚è§[Providers | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/integrations/providers/)

```python
from langchain.chat_models import ChatOpenAI
```

å£°æ˜ä¸€ä¸ªmodel

```python
chat = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')
```

### Prompt template

ä½¿ç”¨LangChainæ„é€ promptæ¨¡æ¿ï¼Œå°†éœ€è¦æ”¹åŠ¨çš„éƒ¨åˆ†æŠ½è±¡æˆå˜é‡ï¼Œå…·ä½“ä½¿ç”¨æ—¶æŠ½è±¡æˆæ‰€éœ€è¦çš„å†…å®¹ã€‚è¾¾åˆ°ä¸€æ¬¡å®šä¹‰ï¼Œå¤šæ¬¡ä½¿ç”¨çš„æ•ˆæœã€‚

**é¦–å…ˆå®šä¹‰æ¨¡æ¿å­—ç¬¦ä¸²ï¼š**

```python
template_string = """Translate the text \
that is delimited by triple backticks \
into a style that is {style}. \
text: ```{text}```
"""
```

ä»`langchain.prompts`å¯¼å…¥`ChatPromptTemplate`ç”¨æ¥å®ä¾‹åŒ–promptæ¨¡æ¿ã€‚

```python
from langchain.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_template(template_string)
```

è¾“å‡º`prompt_template`å¯ä»¥å‘ç°ï¼Œ`input_variables`å°±æ˜¯`template_string`ä¸­å®šä¹‰çš„`{text}`å’Œ`{style}`ã€‚åç»­ä½¿ç”¨ä¸­ï¼Œæ›¿æ¢`{text}`å’Œ`{style}`å¯æ–¹ä¾¿åœ°æ„é€ ä¸åŒçš„promptã€‚

![](../assets/images/llm_develop/langchain-2.png)

æˆ‘ä»¬ä½¿ç”¨`prompt_template`æ„é€ coustomer promptï¼Œå¹¶ä½¿ç”¨`chat`è°ƒç”¨'gpt-3.5-turbo'è·å¾—responseã€‚

**å®šä¹‰styleå’Œtext**

```python
# style
customer_style = """American English \
in a calm and respectful tone
"""

# text
customer_email = """
Arrr, I be fuming that me blender lid \
flew off and splattered me kitchen walls \
with smoothie! And to make matters worse, \
the warranty don't cover the cost of \
cleaning up me kitchen. I need yer help \
right now, matey!
"""
```

**æ„é€ customer prompt**

```python
customer_messages = prompt_template.format_messages(
                    style=customer_style,
                    text=customer_email)
```

**è°ƒç”¨'gpt-3.5-turbo'å°†`customer_email`è½¬æ¢ä¸º`customer_style`é£æ ¼**

```
customer_response = chat(customer_messages)
```

![](../assets/images/llm_develop/langchain-3.png)

### Parse the LLM output string into a Python dictionary

Parseræ˜¯LangChainèƒ½å¤Ÿæˆé“¾çš„å…³é”®ã€‚å› ä¸ºå®ƒä¼šå°†LLMçš„è¾“å‡ºè§£ææˆä½ æ‰€éœ€è¦çš„æ ¼å¼ï¼Œä¾‹å¦‚å­—å…¸ã€‚å°†æ­¤è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ¨¡å—çš„è¾“å…¥ï¼Œä»è€Œå¯ä»¥å°†ä¸¤ä¸ªæ¨¡å—å…³è”èµ·æ¥ã€‚

**å¯¼å…¥å¿…è¦çš„åº“ï¼š**

ä»`langchain`åº“çš„`output_parsers`æ¨¡å—ä¸­å¯¼å…¥`ResponseSchema`å’Œ`StructuredOutputParser`

- `ResponseSchema`ç”¨äºå®šä¹‰å’ŒéªŒè¯è¾“å‡ºçš„é¢„æœŸç»“æ„ï¼›

- `StructuredOutputParser`ç”¨äºå°†è¾“å‡ºè§£æä¸ºç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºåç»­å¤„ç†å’Œåˆ†æã€‚

```python
from langchain.output_parsers import ResponseSchema
from langchain.output_parsers import StructuredOutputParser
```

**ç”Ÿæˆå¯¹åº”æ ¼å¼çš„Schemaï¼š**

å‡è®¾LLMçš„è¾“å‡ºæ ¼å¼æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œæœ‰ä¸‰ä¸ªkeyåˆ†åˆ«ä¸ºgiftã€delivery_daysã€å’Œprice_valueã€‚

```python
{
  "gift": False,
  "delivery_days": 5,
  "price_value": "pretty affordable!"
}
```

ä½¿ç”¨`ResponseSchema`ç”ŸæˆSchemaï¼š

```python
gift_schema = ResponseSchema(name="gift",
                             description="Was the item purchased\
                             as a gift for someone else? \
                             Answer True if yes,\
                             False if not or unknown.")
delivery_days_schema = ResponseSchema(name="delivery_days",
                                      description="How many days\
                                      did it take for the product\
                                      to arrive? If this \
                                      information is not found,\
                                      output -1.")
price_value_schema = ResponseSchema(name="price_value",
                                    description="Extract any\
                                    sentences about the value or \
                                    price, and output them as a \
                                    comma separated Python list.")

response_schemas = [gift_schema, 
                    delivery_days_schema,
                    price_value_schema]
```

**ç”Ÿæˆè§£æLLM responseçš„parserï¼š**

```python
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
```

**è·å–è¾“å‡ºæ ¼å¼è¯´æ˜ï¼š**

```python
format_instructions = output_parser.get_format_instructions()
```

![](../assets/images/llm_develop/langchain-4.png)

**ç”Ÿæˆpromptï¼š**

å®šä¹‰promptæ¨¡æ¿ï¼Œç”ŸæˆåŒ…å«æ–‡æœ¬å’Œformat_instructionsçš„promptã€‚

```python
review_template_2 = """\
For the following text, extract the following information:

gift: Was the item purchased as a gift for someone else? \
Answer True if yes, False if not or unknown.

delivery_days: How many days did it take for the product\
to arrive? If this information is not found, output -1.

price_value: Extract any sentences about the value or price,\
and output them as a comma separated Python list.

text: {text}

{format_instructions}
"""

prompt = ChatPromptTemplate.from_template(template=review_template_2)

messages = prompt.format_messages(text=customer_review, 
                                format_instructions=format_instructions)
```

**è°ƒç”¨LLMç”Ÿæˆresponse**

```python
response = chat(messages)
```

`response.content`ä¸º`str`æ ¼å¼

![](../assets/images/llm_develop/langchain-6.png)

**parserè§£æä¸ºdictæ ¼å¼**

```python
output_dict = output_parser.parse(response.content)
```

![](../assets/images/llm_develop/langchain-7.png)

## Memory

è¯­è¨€æ¨¡å‹æ˜¯æ— çŠ¶æ€çš„ï¼Œç”¨æˆ·æ¯ä¸€æ¬¡ä¸è¯­è¨€æ¨¡å‹çš„äº¤äº’éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæ¢å¥è¯è¯´ï¼Œè¯­è¨€æ¨¡å‹å¹¶ä¸è®°å¾—åˆ°ç›®å‰ä¸ºæ­¢çš„å†å²å¯¹è¯ã€‚å› æ­¤ï¼Œåœ¨æ„å»ºåº”ç”¨ç¨‹åºæ—¶ï¼Œå¯¹è¯ç¼ºä¹çœŸæ­£çš„è¿ç»­æ€§ã€‚LangChainçš„Memoryæ¨¡å—å¯ä»¥å°†å…ˆå‰çš„å¯¹è¯åµŒå…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­ï¼Œä½¿å¯¹è¯å…·æœ‰è¿ç»­æ€§ã€‚

LangChainå…·æœ‰å¤šç§Memoryï¼Œæœ¬è¯¾ç¨‹ä¸»è¦ä»‹ç»å…¶ä¸­å››ç§ï¼š

- **ConversationBufferMemory**
- **ConversationBufferWindowMemory**
- **ConversationTokenBufferMemory**
- **ConversationSummaryMemory**

æ›´å¤šMemoryè¯·å‚è€ƒAPIæ‰‹å†Œï¼š[memory](https://api.python.langchain.com/en/latest/langchain/memory.html)

### ConversationBufferMemory

**å¯¼å…¥Model, Chainå’ŒMemory**

```python
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
```

**æ„å»ºConversation**

```python
llm = ChatOpenAI(temperature=0.0, model=llm_model)
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=llm, 
    memory = memory,
    verbose=True
)
```

**è°ƒç”¨`.predict()`å¯åŠ¨å¯¹è¯**

```python
conversation.predict(input="Hi, my name is Andrew")
conversation.predict(input="What is 1+1?")
conversation.predict(input="What is my name?")
```

æˆ‘ä»¬è¿ç»­è¿›è¡Œä¸‰è½®å¯¹è¯ï¼Œçœ‹çœ‹æ¨¡å‹å†…éƒ¨åˆ°åº•å­˜å‚¨äº†äº›ä»€ä¹ˆã€‚

![](../assets/images/llm_develop/langchain-8.png)

æ¨¡å‹å­˜å‚¨äº†å†å²å¯¹è¯çš„æ‰€æœ‰å†…å®¹ï¼Œå› æ­¤å®ƒçŸ¥é“ç”¨æˆ·çš„åå­—æ˜¯Andrewã€‚

è¯¦æƒ…è¯·çœ‹ï¼š[ConversationBufferMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html#langchain.memory.buffer.ConversationBufferMemory)

### ConversationBufferWindowMemory

[ConversationBufferWindowMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html)åªä¿ç•™æœ€è¿‘çš„ä¸€ä¸ªçª—å£å¤§å°çš„å¯¹è¯ã€‚

å£°æ˜`k=1`çš„`ConversationBufferWindowMemory`

```python
from langchain.memory import ConversationBufferWindowMemory

llm = ChatOpenAI(temperature=0.0, model=llm_model)
memory = ConversationBufferWindowMemory(k=1)
conversation = ConversationChain(
    llm=llm, 
    memory = memory,
    verbose=False
)
```

è¿ç»­è¿›è¡Œä¸‰è½®å¯¹è¯

```python
conversation.predict(input="Hi, my name is Andrew")
conversation.predict(input="What is 1+1?")
conversation.predict(input="What is my name?")
```

![](../assets/images/llm_develop/langchain-9.png)

æˆ‘ä»¬è®¾ç½®çª—å£çš„å¤§å°ä¸º`k=1`ï¼Œæ¨¡å‹åªå­˜å‚¨æœ€è¿‘çš„ä¸€è½®å¯¹è¯ï¼Œæ‰€ä»¥æ¨¡å‹å¹¶ä¸çŸ¥é“ç”¨æˆ·çš„åå­—ï¼Œè™½ç„¶ç”¨æˆ·å·²ç»å‘Šè¯‰è¿‡å®ƒï¼Œä½†æ¨¡å‹å¹¶æ²¡æœ‰å­˜å‚¨ã€‚

### ConversationTokenBufferMemory

[ConversationTokenBufferMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.token_buffer.ConversationTokenBufferMemory.html)ä»tokenæ•°é‡ä¸Šé™åˆ¶Memoryçš„å¤§å°ï¼Œå­˜å‚¨æœ€è¿‘çš„`max_token_limit`ä¸ªtokenã€‚

```python
from langchain.memory import ConversationTokenBufferMemory

memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)
```

### ConversationSummaryMemory

[ConversationSummaryMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.summary.ConversationSummaryMemory.html)å­˜å‚¨æœ€è¿‘å†å²å¯¹è¯çš„æ‘˜è¦ï¼Œè€Œä¸æ˜¯åŸå§‹å¯¹è¯ã€‚åŒæ ·ï¼Œæ‘˜è¦ä¸èƒ½è¶…è¿‡`max_token_limit`ä¸ªtokenã€‚

```python
from langchain.memory import ConversationSummaryBufferMemory

memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)
```

## Chains

[é“¾ï¼ˆchainï¼‰](https://python.langchain.com/api_reference/langchain/chains.html)æ˜¯LangChainä¸­æœ€é‡è¦çš„ç»„ä»¶ï¼Œå°†LLMå’Œpromptç»“åˆåœ¨ä¸€èµ·ã€‚æˆ‘ä»¬å¯ä»¥å°†å¤šä¸ªé“¾è¿æ¥åœ¨ä¸€èµ·ï¼Œåœ¨æ–‡æœ¬æˆ–è€…æ•°æ®ä¸Šè¿›è¡Œä¸€ç³»åˆ—çš„æ“ä½œã€‚

### LLMChain

[LLMChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain)æ˜¯ç®€å•è€Œå¼ºå¤§çš„é“¾ï¼Œæ˜¯å…¶ä»–å¤æ‚é“¾çš„åŸºç¡€ã€‚

**å¯¼å…¥llm, prompt template, chain**

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
```

**åˆ›å»ºllmå’Œprompt template**

```python
llm = ChatOpenAI(temperature=0.9, model=llm_model)

prompt = ChatPromptTemplate.from_template(
    "What is the best name to describe \
    a company that makes {product}?"
)
```

**åˆ›å»ºä¸€ä¸ªLLMChainå®ä¾‹ï¼Œå®ƒå°†ä¸€ä¸ªllmå’Œä¸€ä¸ªprompt templateç»“åˆèµ·æ¥**

```python
chain = LLMChain(llm=llm, prompt=prompt)
```

**è°ƒç”¨LLMChainå®ä¾‹çš„runæ–¹æ³•ï¼Œå°†productä½œä¸ºè¾“å…¥ä¼ é€’ç»™é“¾ï¼Œå¹¶æ‰§è¡Œé“¾ä¸­å®šä¹‰çš„æµç¨‹**

```
product = "Queen Size Sheet Set"
chain.run(product)
```

### SimpleSequentialChain

[SimpleSequentialChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sequential.SimpleSequentialChain.html#langchain.chains.sequential.SimpleSequentialChain)æ˜¯é¡ºåºé“¾æœ€ç®€å•çš„å½¢å¼ï¼Œå…¶ä¸­æ¯ä¸ªæ­¥éª¤éƒ½æœ‰ä¸€ä¸ªå•ä¸€çš„è¾“å…¥/è¾“å‡ºï¼Œå¹¶ä¸”ä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºæ˜¯ä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ã€‚

**å¯¼å…¥SimpleSequentialChain**

```python
from langchain.chains import SimpleSequentialChain
```

**åˆ›å»ºä¸¤ä¸ªLLMChainå®ä¾‹ä½œä¸ºå­é“¾**

```py
llm = ChatOpenAI(temperature=0.9, model=llm_model)

# prompt template 1
first_prompt = ChatPromptTemplate.from_template(
    "What is the best name to describe \
    a company that makes {product}?"
)

# Chain 1
chain_one = LLMChain(llm=llm, prompt=first_prompt)
```

```python
# prompt template 2
second_prompt = ChatPromptTemplate.from_template(
    "Write a 20 words description for the following \
    company:{company_name}"
)
# chain 2
chain_two = LLMChain(llm=llm, prompt=second_prompt)
```

**ä½¿ç”¨SimpleSequentialChainå°†ä¸¤ä¸ªå­é“¾ç»„è£…èµ·æ¥**

```
overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],
                                             verbose=True
                                            )
```

**è°ƒç”¨runæ–¹æ³•æ‰§è¡Œæµç¨‹**

```python
overall_simple_chain.run(product)
```

### SequentialChain

[SequentialChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sequential.SequentialChain.html#langchain.chains.sequential.SequentialChain)æ˜¯æ›´é€šç”¨çš„é¡ºåºé“¾å½¢å¼ï¼Œå…è®¸å¤šä¸ªè¾“å…¥å’Œè¾“å‡ºã€‚

**å¯¼å…¥SequentialChain**

```python
from langchain.chains import SequentialChain
```

**åˆ›å»ºå››ä¸ªLLMChainå®ä¾‹ä½œä¸ºå­é“¾**

```python
llm = ChatOpenAI(temperature=0.9, model=llm_model)

# prompt template 1: translate to english
first_prompt = ChatPromptTemplate.from_template(
    "Translate the following review to english:"
    "\n\n{Review}"
)
# chain 1: input= Review and output= English_Review
chain_one = LLMChain(llm=llm, prompt=first_prompt, 
                     output_key="English_Review"
                    )
```

```python
second_prompt = ChatPromptTemplate.from_template(
    "Can you summarize the following review in 1 sentence:"
    "\n\n{English_Review}"
)
# chain 2: input= English_Review and output= summary
chain_two = LLMChain(llm=llm, prompt=second_prompt, 
                     output_key="summary"
                    )
```

```python
# prompt template 3: translate to english
third_prompt = ChatPromptTemplate.from_template(
    "What language is the following review:\n\n{Review}"
)
# chain 3: input= Review and output= language
chain_three = LLMChain(llm=llm, prompt=third_prompt,
                       output_key="language"
                      )
```

```python
# prompt template 4: follow up message
fourth_prompt = ChatPromptTemplate.from_template(
    "Write a follow up response to the following "
    "summary in the specified language:"
    "\n\nSummary: {summary}\n\nLanguage: {language}"
)
# chain 4: input= summary, language and output= followup_message
chain_four = LLMChain(llm=llm, prompt=fourth_prompt,
                      output_key="followup_message"
                     )
```

æ¯ä¸ªå­é“¾éƒ½æŒ‡å®šäº†`output_key`æ ‡è¯†å­é“¾çš„è¾“å‡ºï¼Œæ¯ä¸ªpromptä¸­çš„å ä½ç¬¦{xxx}è¡¨ç¤ºè¯¥å­é“¾çš„è¾“å…¥ã€‚è¾“å…¥è¾“å‡º

å˜é‡çš„åç§°è¦ä¸¥æ ¼å¯¹åº”ï¼Œå¦åˆ™ä¼šå‡ºç°key errorã€‚

**åˆ›å»ºSequentialChain**

```python
# overall_chain: input= Review 
# and output= English_Review,summary, followup_message
overall_chain = SequentialChain(
    chains=[chain_one, chain_two, chain_three, chain_four],
    input_variables=["Review"],
    output_variables=["English_Review", "summary","language","followup_message"],
    verbose=True
)
```

- **chains**ï¼šé¡ºåºé“¾ä¸­åŒ…å«çš„å­é“¾åˆ—è¡¨ï¼›
- **input_variables**ï¼šè¾“å…¥å˜é‡åˆ—è¡¨ï¼Œç”±äºç¬¬ä¸€ä¸ªå­é“¾çš„è¾“å…¥æ˜¯`{Review}`ï¼Œå› æ­¤è¾“å…¥å˜é‡ä¸º`["Review"]`;
- **output_variables**ï¼šè¾“å‡ºå˜é‡åˆ—è¡¨ã€‚

**æ‰§è¡Œé¡ºåºé“¾**

```python
review = df.Review[5]
overall_chain(review)
```

![](../assets/images/llm_develop/langchain-10.png)

è¾“å‡º`output_variables`ä¸­æŒ‡å®šçš„å˜é‡`["English_Review", "summary","language","followup_message"]`ã€‚

### Router Chain

Router Chainï¼ˆè·¯ç”±é“¾ï¼‰å…è®¸æ ¹æ®è¾“å…¥çš„promptä»ç»™å®šçš„ä¸€ç»„é“¾ä¸­åŠ¨æ€é€‰æ‹©ä¸€ä¸ªé¢„å®šä¹‰çš„å­é“¾ã€‚

**å®šä¹‰ä¸€ç»„prompt template**

```python
physics_template = """You are a very smart physics professor. \
You are great at answering questions about physics in a concise\
and easy to understand manner. \
When you don't know the answer to a question you admit\
that you don't know.

Here is a question:
{input}"""


math_template = """You are a very good mathematician. \
You are great at answering math questions. \
You are so good because you are able to break down \
hard problems into their component parts, 
answer the component parts, and then put them together\
to answer the broader question.

Here is a question:
{input}"""

history_template = """You are a very good historian. \
You have an excellent knowledge of and understanding of people,\
events and contexts from a range of historical periods. \
You have the ability to think, reflect, debate, discuss and \
evaluate the past. You have a respect for historical evidence\
and the ability to make use of it to support your explanations \
and judgements.

Here is a question:
{input}"""


computerscience_template = """ You are a successful computer scientist.\
You have a passion for creativity, collaboration,\
forward-thinking, confidence, strong problem-solving capabilities,\
understanding of theories and algorithms, and excellent communication \
skills. You are great at answering coding questions. \
You are so good because you know how to solve a problem by \
describing the solution in imperative steps \
that a machine can easily interpret and you know how to \
choose a solution that has a good balance between \
time complexity and space complexity. 

Here is a question:
{input}"""
```

**å¯¹æ¯ä¸ªtemplateè¿›è¡Œå‘½åå’Œæè¿°ï¼Œå°è£…æˆå­—å…¸**

```python
prompt_infos = [
    {
        "name": "physics", 
        "description": "Good for answering questions about physics", 
        "prompt_template": physics_template
    },
    {
        "name": "math", 
        "description": "Good for answering math questions", 
        "prompt_template": math_template
    },
    {
        "name": "History", 
        "description": "Good for answering history questions", 
        "prompt_template": history_template
    },
    {
        "name": "computer science", 
        "description": "Good for answering computer science questions", 
        "prompt_template": computerscience_template
    }
]
```

**å¯¼å…¥MultiPromptChainï¼Œ LLMRouterChainï¼ŒRouterOutputParserï¼ŒPromptTemplate**

```python
from langchain.chains.router import MultiPromptChain
from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser
from langchain.prompts import PromptTemplate
```

**ä¸º`prompt_infos`ä¸­æ¯ä¸ªpromptåˆ›å»ºå­é“¾ï¼Œå¹¶åŠ å…¥`destination_chains`**

```python
destination_chains = {}
for p_info in prompt_infos:
    name = p_info["name"]
    prompt_template = p_info["prompt_template"]
    prompt = ChatPromptTemplate.from_template(template=prompt_template)
    chain = LLMChain(llm=llm, prompt=prompt)
    destination_chains[name] = chain  
    
destinations = [f"{p['name']}: {p['description']}" for p in prompt_infos]
destinations_str = "\n".join(destinations)
```

**åˆ›å»ºé»˜è®¤é“¾ï¼Œå½“æ— æ³•å†³å®šè°ƒç”¨å“ªä¸€æ¡å­é“¾æ—¶ï¼Œè°ƒç”¨é»˜è®¤é“¾**

```python
default_prompt = ChatPromptTemplate.from_template("{input}")
default_chain = LLMChain(llm=llm, prompt=default_prompt)
```

**æ„å»ºè·¯ç”±é“¾**

```
router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(
    destinations=destinations_str
)
router_prompt = PromptTemplate(
    template=router_template,
    input_variables=["input"],
    output_parser=RouterOutputParser(),
)

router_chain = LLMRouterChain.from_llm(llm, router_prompt)
```

`LLMRouterChain`æ ¹æ®è¾“å…¥åŠ¨æ€åœ°å°†ä»»åŠ¡è·¯ç”±åˆ°é€‚å½“çš„å­é“¾ï¼Œå³ä¸åŒçš„`LLMChain`ã€‚

**å°è£…æ€»ä½“é“¾è·¯**

```python
chain = MultiPromptChain(router_chain=router_chain, 
                         destination_chains=destination_chains, 
                         default_chain=default_chain, verbose=True
                        )
```

`MultiPromptChain`å…è®¸æ ¹æ®ä¸åŒçš„è¾“å…¥å†…å®¹ï¼ŒåŠ¨æ€é€‰æ‹©ä¸åŒçš„é“¾è·¯ã€‚

**æµ‹è¯•è·¯ç”±é“¾**

```python
chain.run("What is black body radiation?") # æé—®ç‰©ç†é—®é¢˜
```

```wiki
# è¢«è·¯ç”±åˆ°ç‰©ç†é“¾è·¯
> Entering new MultiPromptChain chain...
physics: {'input': 'What is black body radiation?'}
> Finished chain.
"Black body radiation is the type of electromagnetic radiation that is emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation, regardless of frequency or angle of incidence. The radiation has a specific spectrum and intensity that depends only on the body's temperature, which is assumed to be uniform and constant. This phenomenon was first explained by Max Planck in 1900, and it is a foundational concept in quantum mechanics."
```

```python
chain.run("Why does every cell in our body contain DNA?") # æé—®ç”Ÿç‰©é—®é¢˜
```

```wiki
# ç”±äºæ²¡æœ‰â€œç”Ÿç‰©â€ç±»çš„prompt templateï¼Œå› æ­¤è¢«è·¯ç”±åˆ°é»˜è®¤é“¾è·¯ã€‚
> Entering new MultiPromptChain chain...
None: {'input': 'Why does every cell in our body contain DNA?'}
> Finished chain.
'DNA, or deoxyribonucleic acid, is the hereditary material in humans and almost all other organisms. It contains the instructions needed for an organism to develop, survive and reproduce. These instructions are found inside every cell, and are passed down from parents to their children.\n\nDNA is organized into structures called chromosomes and is divided into segments known as genes. Each gene contains a specific set of instructions that code for particular proteins that perform various functions in the body.\n\nTherefore, every cell in our body contains DNA because it is essential for life. It provides the instructions for the growth, development, function and reproduction of cells. Without DNA, our cells would not know what to do or how to function, and life as we know it would not exist.'
```

## Question and Answer

ä½¿ç”¨LLMæ„å»ºåŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿæ˜¯ç›®å‰æœ€å¸¸è§çš„åœºæ™¯ä¹‹ä¸€ã€‚ç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œä½¿ç”¨LLMå›ç­”ç”¨æˆ·æœ‰å…³è¯¥æ–‡æœ¬çš„é—®é¢˜ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·å¯¹æ–‡æœ¬æœ‰æ›´æ·±çš„ç†è§£æˆ–è€…æå–ç”¨æˆ·å…³å¿ƒçš„å†…å®¹ã€‚è¯¥åœºæ™¯å°†LLMä¸å¤–éƒ¨æ•°æ®ç»“åˆèµ·æ¥ï¼Œæé«˜LLMä½¿ç”¨çš„çµæ´»æ€§å¹¶æ‰©å¤§äº†é€‚ç”¨èŒƒå›´ã€‚

### LangChain: Q&A over Documents

ä½¿ç”¨LangChainç´¢å¼•æ­å»ºåŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿã€‚

**åˆ›å»ºæ–‡æ¡£åŠ è½½å™¨**

ä»`.csv`æ–‡æ¡£ä¸­è¯»å–æ•°æ®ï¼Œåˆ›å»º`CSVLoader`

```python
file = 'OutdoorClothingCatalog_1000.csv'
loader = CSVLoader(file_path=file)
```

**åˆ›å»ºç´¢å¼•**

åˆ›å»ºäº†æ–‡æ¡£åŠ è½½å™¨loderä¹‹åï¼Œè¿˜éœ€è¦åˆ›å»ºç”¨äºæ£€ç´¢æ–‡æ¡£å†…å®¹çš„ç´¢å¼•`index`ã€‚

`VectorstoreIndexCreator`ç”¨äºåˆ›å»ºå’Œç®¡ç†å‘é‡å­˜å‚¨ç´¢å¼•ï¼Œä¾¿äºå¯¹å¤§é‡æ–‡æ¡£è¿›è¡Œé«˜æ•ˆæ£€ç´¢ã€‚å®ƒé€šè¿‡ä¸å‘é‡æ•°æ®åº“é›†æˆï¼Œå¸®åŠ©ç”¨æˆ·æ„å»ºä¸€ä¸ªå¯æŸ¥è¯¢çš„ç´¢å¼•ã€‚æˆ‘ä»¬ä½¿ç”¨çš„å‘é‡æ•°æ®åº“æ˜¯`DocArrayInMemorySearch`ï¼Œå®ƒåŸºäº DocArray çš„å†…å­˜å­˜å‚¨åŠŸèƒ½ï¼Œå°†æ•´ä¸ªæ–‡æ¡£ä»¥å‘é‡çš„å½¢å¼å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œç”¨äºåœ¨æœ¬åœ°å†…å­˜ä¸­å­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡ï¼Œé€‚åˆå°è§„æ¨¡æˆ–åŸå‹åŒ–çš„è¯­ä¹‰æœç´¢ä»»åŠ¡ã€‚æœ€åè°ƒç”¨`.from_loaders`æ–¹æ³•ä»`loader`åˆ›å»ºç´¢å¼•ã€‚

```python
from langchain.indexes import VectorstoreIndexCreator

index = VectorstoreIndexCreator(
    vectorstore_cls=DocArrayInMemorySearch
).from_loaders([loader])
```

æ¥ä¸‹æ¥ç›´æ¥ä½¿ç”¨ç´¢å¼•å¯¹æ–‡æ¡£è¿›è¡Œé—®ç­”ï¼š

```python
query ="Please list all your shirts with sun protection \
in a table in markdown and summarize each one."

llm_replacement_model = OpenAI(temperature=0, 
                               model='gpt-3.5-turbo-instruct')

response = index.query(query, 
                       llm = llm_replacement_model)
                       
display(Markdown(response))
```

![](../assets/images/llm_develop/langchain-11.png)

llmè¿”å›4ä»¶å…·æœ‰é˜²æ™’åŠŸèƒ½çš„è¡¬è¡«ï¼Œå¹¶ä¸”å¯¹æ¯ä¸€ä»¶è¡¬è¡«éƒ½è¿›è¡Œäº†æ€»ç»“ï¼Œæœ€åä»¥markdownè¡¨æ ¼æ ¼å¼è¾“å‡ºï¼Œæ»¡è¶³`query`è¦æ±‚ã€‚

### Step By Step

ä½¿ç”¨`index.query()`æ–¹æ³•åªç”¨ä¸€è¡Œä»£ç å°±å¯ä»¥å®ç°æ–‡æ¡£é—®ç­”åŠŸèƒ½ï¼Œæœ¬èŠ‚æˆ‘ä»¬ä¸€èµ·æ¥æ¢ç´¢å…¶èƒŒåçš„åŸç†ã€‚

LLMä¸€æ¬¡åªèƒ½å¤„ç†å‡ åƒä¸ªå•è¯ï¼Œå½“é‡åˆ°è¾ƒå¤§è§„æ¨¡çš„æ–‡æ¡£æ—¶ï¼Œå¦‚ä½•ä½¿LLMå›ç­”å…³äºè¯¥æ–‡æ¡£çš„æ‰€æœ‰é—®é¢˜ï¼Ÿè¿™å°±éœ€è¦â€™embeddingsâ€˜å’Œâ€˜vector databaseâ€™ï¼Œæˆ‘ä»¬å…ˆä»‹ç»â€™embeddingsâ€˜å’Œâ€˜vector databaseâ€™çš„æ¦‚å¿µï¼Œç„¶åå†åˆ›å»ºæ–‡æ¡£é—®ç­”ç³»ç»Ÿstep by stepã€‚

#### Embeddings

Embeddingæ˜¯æŒ‡å°†è¯æ±‡ã€çŸ­è¯­ã€æ–‡æ¡£æˆ–å…¶ä»–ç±»å‹çš„æ•°æ®è½¬æ¢ä¸ºå®æ•°å‘é‡çš„è¿‡ç¨‹ã€‚ç›¸ä¼¼çš„è¯æˆ–æ¦‚å¿µåœ¨å‘é‡ç©ºé—´ä¸­å½¼æ­¤æ¥è¿‘ã€‚

![](../assets/images/llm_develop/embeddings.png)

å›¾ä¸­å¥å­1ï¼‰2ï¼‰éƒ½æ˜¯å…³äºåŠ¨ç‰©çš„ï¼Œå®ƒä»¬å…·æœ‰ç›¸ä¼¼çš„è¯­ä¹‰ï¼Œembeddingå‘é‡åœ¨ç©ºé—´ä¸­çš„ä½ç½®æ¯”è¾ƒæ¥è¿‘ã€‚å¥å­3ï¼‰æ˜¯å…³äºæ±½è½¦çš„ï¼Œembeddingå‘é‡ä¸å‰ä¸¤å¥è¯è·ç¦»è¾ƒè¿œã€‚

#### Vector Database

åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æŠŠ`.csv`æ–‡æ¡£å­˜å…¥å†…å­˜è¿›è¡Œæ£€ç´¢ã€‚å¯¹äºå¤§è§„æ¨¡æ–‡æ¡£ï¼Œå†…å­˜æ˜¯è¿œè¿œä¸å¤Ÿçš„ï¼Œè¿™æ—¶å€™å°±è¦ç”¨åˆ°Vector Databaseï¼ˆå‘é‡æ•°æ®åº“ï¼‰ã€‚

![](../assets/images/llm_develop/vector_database_1.png)

**æ–‡æ¡£æ˜¯å¦‚ä½•å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“çš„ï¼Ÿ**

æ–‡æ¡£é¦–å…ˆè¢«åˆ’åˆ†ä¸ºå¾ˆå¤šchunkï¼ˆå—ï¼‰ï¼Œç„¶åå¯¹æ¯ä¸ªchunkä½œembeddingï¼Œæœ€åå°†embeddingå‘é‡å’ŒåŸæœ¬çš„chunkä¸€å¹¶å­˜å…¥æ•°æ®åº“ã€‚

#### å‘æ–‡æ¡£æé—®

ç³»ç»Ÿå°†ç”¨æˆ·queryè½¬åŒ–ä¸ºembeddingå‘é‡ï¼Œå°†è¯¥å‘é‡ä¸å‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰å‘é‡è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºå‰nä¸ªæœ€ç›¸ä¼¼çš„å‘é‡ï¼Œå°†å…¶åŸå§‹chunkç»„åˆèµ·æ¥å–‚ç»™LLMç”Ÿæˆç­”æ¡ˆã€‚

![](../assets/images/llm_develop/vector_database_2.png)

æ¥ä¸‹æ¥æˆ‘ä»¬å¯¹ä¹‹å‰çš„æ•°æ®é›†ä½œembeddingï¼Œç„¶ååˆ›å»ºé—®ç­”é“¾ï¼ˆchainï¼‰å¯¹æ–‡æ¡£è¿›è¡Œæé—®ã€‚

```python
# åŠ è½½æ–‡æ¡£
from langchain.document_loaders import CSVLoader
loader = CSVLoader(file_path=file)
docs = loader.load()

# åˆ›å»ºembeddings
from langchain.embeddings import OpenAIEmbeddings
embeddings = OpenAIEmbeddings()

# åˆ›å»ºå‘é‡æ•°æ®åº“
db = DocArrayInMemorySearch.from_documents(
    docs, 
    embeddings
)

# åˆ›å»ºæ£€ç´¢å™¨
retriever = db.as_retriever()

# åŠ è½½llmæ¨¡å‹
llm = ChatOpenAI(temperature = 0.0, model='gpt-4')

# æ„å»ºåŸºäºæ£€ç´¢çš„é—®ç­”ç³»ç»Ÿ
qa_stuff = RetrievalQA.from_chain_type(
    llm=llm, 
    chain_type="stuff", 
    retriever=retriever, 
    verbose=True
)

query = "Please list all your shirts with sun protection in a table \
in markdown and summarize each one."

response = qa_stuff.run(query) 
```

```python
display(Markdown(response))
```

![](../assets/images/llm_develop/langchain-12.png)

`RetrievalQA`æ˜¯LangChainä¸­ç”¨äºæ„å»ºåŸºäºæ£€ç´¢çš„é—®ç­”ç³»ç»Ÿçš„å·¥å…·ã€‚å®ƒç»“åˆäº†æ–‡æ¡£æ£€ç´¢å’ŒLLMçš„èƒ½åŠ›ï¼Œä¸ºç”¨æˆ·æä¾›é«˜æ•ˆçš„çŸ¥è¯†é—®ç­”ä½“éªŒã€‚å› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ–‡æœ¬è¾ƒå°ï¼Œæ–‡æœ¬å¤„ç†æ¨¡å¼`chain_type`é‡‡ç”¨`stuff`ï¼Œå°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ç›´æ¥æ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¸€æ¬¡æ€§è¾“å…¥ç»™LLMã€‚å¦å¤–ï¼Œ`chain_type`è¿˜æœ‰`map_reduce`, `refine`å’Œ`map_rerank`ä¸‰ç§æ¨¡å¼å¯é€‰ã€‚

![.](../assets/images/llm_develop/additionalmethods.png)

**map_reduce**ï¼šå¯¹æ¯ä¸ªæ£€ç´¢åˆ°çš„chunkåˆ†åˆ«ç”Ÿæˆç­”æ¡ˆï¼ˆmapé˜¶æ®µ)ï¼Œç„¶åå¯¹è¿™äº›ç­”æ¡ˆè¿›è¡Œæ•´åˆï¼ˆreduceé˜¶æ®µï¼‰ï¼›

**refine**ï¼šå…ˆæ€»ç»“å­ä¸€ä¸ªchunkï¼Œç„¶åå°†æ€»ç»“å†…å®¹å’Œç¬¬äºŒä¸ªchunkä¸€èµ·åšæ€»ç»“ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æ€»ç»“å®Œæ‰€æœ‰chunkï¼›

**map_rerank**ï¼šå¯¹æ¯ä¸€ä¸ªchunkè¿›è¡Œæ€»ç»“å¹¶è¯„åˆ†ï¼Œé€‰æ‹©è¯„åˆ†æœ€é«˜çš„ä½œä¸ºæœ€ç»ˆç»“æœã€‚

## Evaluation

è¯„ä¼°æ˜¯æ£€éªŒLLMé—®ç­”è´¨é‡çš„å…³é”®ã€‚å½“ä½ æ”¹å˜äº†ç³»ç»Ÿçš„å®ç°ï¼Œä¾‹å¦‚æ›´æ¢äº†LLMã€æ”¹å˜ä½¿ç”¨å‘é‡æ•°æ®åº“çš„ç­–ç•¥ï¼Œæˆ–è€…ä¿®æ”¹äº†ç³»ç»Ÿå‚æ•°ï¼Œä½ è¯¥å¦‚ä½•çŸ¥é“ç³»ç»Ÿæ˜¯å˜å¥½äº†è¿˜å¥½å˜å·®äº†â€”â€”æˆ‘ä»¬éœ€è¦å¯¹å®ƒè¿›è¡Œè¯„ä¼°ã€‚

ä¸Šä¸€èŠ‚å·²ç»ä½¿ç”¨LangChainæ„å»ºäº†åŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿçš„æ­£ç¡®æ€§åˆ°åº•å¦‚ä½•å‘¢ï¼Ÿæœ¬èŠ‚ä»¥è¯„ä¼°åŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿä¸ºä¾‹ï¼Œä»‹ç»è¯„ä¼°LLMç³»ç»Ÿçš„å·¥å…·å’Œæ–¹æ³•ã€‚

**åŸºæœ¬æ€æƒ³**ï¼šä½¿ç”¨LLMå’Œé“¾æœ¬èº«è¯„ä¼°å…¶ä»–LLMã€é“¾å’Œåº”ç”¨ç¨‹åºã€‚

### Create Q&A application

åˆ›å»ºQ&Aç³»ç»Ÿä½œä¸ºè¯„ä¼°çš„LLMåº”ç”¨

```python
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import CSVLoader
from langchain.indexes import VectorstoreIndexCreator
from langchain.vectorstores import DocArrayInMemorySearch

file = 'OutdoorClothingCatalog_1000.csv'
loader = CSVLoader(file_path=file)
data = loader.load()

index = VectorstoreIndexCreator(
    vectorstore_cls=DocArrayInMemorySearch
).from_loaders([loader])

llm = ChatOpenAI(temperature = 0.0, model=llm_model)
qa = RetrievalQA.from_chain_type(
    llm=llm, 
    chain_type="stuff", 
    retriever=index.vectorstore.as_retriever(), 
    verbose=True,
    chain_type_kwargs = {
        "document_separator": "<<<<>>>>>"
    }
)
```

### åˆ›å»ºé—®ç­”æµ‹è¯•é›†

æ ¹æ®æ–‡æ¡£'OutdoorClothingCatalog_1000.csv'å†…å®¹ï¼Œåˆ›å»ºquery-answer æµ‹è¯•å¯¹ä½œä¸ºground truthã€‚

```python
examples = [
    {
        "query": "Do the Cozy Comfort Pullover Set\
        have side pockets?",
        "answer": "Yes"
    },
    {
        "query": "What collection is the Ultra-Lofty \
        850 Stretch Down Hooded Jacket from?",
        "answer": "The DownTek collection"
    }
]
```

å¯ä»¥æ‰‹åŠ¨ç¼–å†™ï¼Œæ›´æ¨èçš„æ–¹æ³•æ˜¯ä½¿ç”¨LLM+Chainç”Ÿæˆground truth query-answer æµ‹è¯•å¯¹ã€‚

```python
from langchain.evaluation.qa import QAGenerateChain

# ä½¿ç”¨QAGenerateChainå’ŒChatOpenAIåˆ›å»ºé—®ç­”ç”Ÿæˆé“¾
example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))

# å–dataä¸­å‰5ä¸ªæ•°æ®ç”Ÿæˆé—®ç­”å¯¹
new_examples = example_gen_chain.apply_and_parse(
    [{"doc": t} for t in data[:5]]
)
```

```python
new_examples[0]

'''
{'query': " According to the document, what is the approximate weight of the Women's Campside Oxfords per pair?\n\n",
 'answer': " The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz."}
 '''
```

### LLM assisted evaluation

```python
# ä½¿ç”¨applyæ–¹æ³•ä¸ºexamplesä¸­çš„æµ‹è¯•é—®é¢˜ç”Ÿæˆç­”æ¡ˆ
predictions = qa.apply(examples)
```

**ä½¿ç”¨LLMè¯„ä¼°ç­”æ¡ˆç›¸ä¼¼æ€§**

`examples`ä½œä¸ºground truthï¼Œ`predictions`ä¸ºLLMç”Ÿæˆçš„ç­”æ¡ˆã€‚ä½¿ç”¨`QAEvalChain`è¯„ä¼°predictionså’Œexamplesçš„ç›¸ä¼¼æ€§ã€‚

```python
from langchain.evaluation.qa import QAEvalChain

llm = ChatOpenAI(temperature=0, model=llm_model)

# åˆ›å»ºè¯„ä¼°é“¾
eval_chain = QAEvalChain.from_llm(llm)

# è¯„ä¼°exampleså’Œpredictionsçš„ç›¸ä¼¼æ€§
graded_outputs = eval_chain.evaluate(examples, predictions)
```

æŸ¥çœ‹è¯„ä¼°ç»“æœ

```python
for i, eg in enumerate(examples):
    print(f"Example {i}:")
    print("Question: " + predictions[i]['query'])
    print("Real Answer: " + predictions[i]['answer'])
    print("Predicted Answer: " + predictions[i]['result'])
    print("Predicted Grade: " + graded_outputs[i]['text'])
    print()
```

```wiki
Example 0:
Question: Do the Cozy Comfort Pullover Set        have side pockets?
Real Answer: Yes
Predicted Answer: Yes, the Cozy Comfort Pullover Set does have side pockets.
Predicted Grade: CORRECT

Example 1:
Question: What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?
Real Answer: The DownTek collection
Predicted Answer: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.
Predicted Grade: CORRECT

Example 2:
Question:  According to the document, what is the approximate weight of the Women's Campside Oxfords per pair?


Real Answer:  The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.
Predicted Answer: The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.
Predicted Grade: CORRECT

......
```



æœ€åæˆ‘ä»¬ç†ä¸€ä¸‹æ€è·¯ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨LLMè‡ªåŠ¨åˆ›å»ºäº†query-answer æµ‹è¯•é›†`examples`ï¼Œæ¥ç€æˆ‘ä»¬è®©LLMå›ç­”æµ‹è¯•é›†ä¸­çš„é—®é¢˜ç”Ÿæˆå›å¤`predictions`ã€‚æ¥ä¸‹æ¥å°†æµ‹è¯•é›†`examples`å’Œå›å¤`predictions`è¿›è¡Œæ¯”å¯¹ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¹Ÿç”±LLMå®Œæˆã€‚æ•´ä¸ªæµç¨‹ä¸­LLMæ—¢å½“â€œè£åˆ¤â€åˆå½“â€œçƒå‘˜â€ï¼Œä½†æ˜¯å®ƒä»¬æ¥è‡ªä¸åŒçš„chainã€‚

## Agents

äººä»¬é€šå¸¸è®¤ä¸ºLLMæ˜¯ä¸€ä¸ªçŸ¥è¯†åº“ï¼Œå› ä¸ºå®ƒçœ‹è¿‡å¾ˆå¤šè®­ç»ƒèµ„æ–™ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜ã€‚LLMçš„èƒ½åŠ›è¿œä¸æ­¢äºæ­¤ï¼Œå®ƒå…¶å®æ˜¯ä¸€ä¸ªâ€œæ¨ç†å¼•æ“â€ï¼Œæ ¹æ®ç”¨æˆ·ä¿¡æ¯å›ç­”é—®é¢˜ã€å†…å®¹æ¨ç†ç”šè‡³åšå†³å®šã€‚æœ¬èŠ‚ä¸»è¦ä»‹ç»å¦‚ä½•åˆ›å»ºå¹¶ä½¿ç”¨Agentï¼Œå¦‚ä½•ä½¿ç”¨Agentè°ƒç”¨å¤–éƒ¨å·¥å…·ä»¥åŠå¦‚ä½•åˆ›å»ºè‡ªå·±çš„å·¥å…·ä¾›Agentè°ƒç”¨ã€‚

### Built-in LangChain tools

åˆ›å»ºä½¿ç”¨LangChainå†…ç½®å·¥å…·â€œllm-mathâ€å’Œ"wikipedia"çš„Agentå®ŒæˆæŸäº›ä»»åŠ¡ã€‚â€œllm-mathâ€å…·æœ‰ä½œæ•°å­¦è¿ç®—çš„èƒ½åŠ›ï¼ŒLLMè°ƒç”¨è¯¥å·¥å…·è§£ç­”æ•°å­¦é—®é¢˜ã€‚"wikipedia"æ˜¯æœç´¢ç»´åŸºç™¾ç§‘çš„å·¥å…·ï¼ŒLLMè¿æ¥ç»´åŸºç™¾ç§‘è¿›è¡Œæœç´¢æŸ¥è¯¢ã€‚

```python
from langchain.agents.agent_toolkits import create_python_agent
from langchain.agents import load_tools, initialize_agent
from langchain.agents import AgentType
from langchain.tools.python.tool import PythonREPLTool
from langchain.python import PythonREPL
from langchain.chat_models import ChatOpenAI

# åˆ›å»ºLLM
llm = ChatOpenAI(temperature=0, model=llm_model)

# å®šä¹‰å·¥å…·
tools = load_tools(["llm-math","wikipedia"], llm=llm)

# åˆ›å»ºAgent
agent= initialize_agent(
    tools, 
    llm, 
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    handle_parsing_errors=True,
    verbose = True)
```

ä½¿ç”¨`initialize_agent`åˆå§‹åŒ–ä»£ç†`agent`ï¼Œä¼ å…¥æ¨¡å‹`llm`å’Œå·¥å…·åˆ—è¡¨`tools`ã€‚

**`agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION`**:

- `AgentType` æ˜¯å®šä¹‰æ™ºèƒ½ä»£ç†ç±»å‹çš„æšä¸¾ã€‚
- `CHAT_ZERO_SHOT_REACT_DESCRIPTION`ç±»å‹è¡¨ç¤ºï¼š
  - ä»£ç†ä»¥å¯¹è¯å½¢å¼ä¸ç”¨æˆ·äº¤äº’ã€‚
  - ä½¿ç”¨ â€œZero-Shotâ€ æ–¹æ³•ï¼šæ— éœ€ç‰¹åˆ«è®­ç»ƒï¼Œç›´æ¥ä¾èµ–è¯­è¨€æ¨¡å‹ç†è§£ä»»åŠ¡ã€‚
  - é‡‡ç”¨ ReAct æ¡†æ¶ï¼šç»“åˆæ¨ç† (Reasoning) å’Œè¡ŒåŠ¨ (Acting) çš„æ–¹å¼å®Œæˆä»»åŠ¡ã€‚
- æ­¤ä»£ç†ä¼šæ ¹æ®å·¥å…·æè¿°æ¨æ–­å…¶åŠŸèƒ½ï¼Œå¹¶é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚

**`handle_parsing_errors=True`**:

- å¯ç”¨é”™è¯¯å¤„ç†æœºåˆ¶ã€‚å¦‚æœä»£ç†åœ¨è§£æç”¨æˆ·è¾“å…¥æˆ–å·¥å…·è¾“å‡ºæ—¶å‘ç”Ÿé”™è¯¯ï¼Œå°†ä¼˜é›…åœ°å¤„ç†é”™è¯¯ï¼Œè€Œä¸ä¼šå¯¼è‡´ç¨‹åºå´©æºƒã€‚

**agentå›ç­”æ•°å­¦é—®é¢˜**

```python
agent("What is the 25% of 300?")
```

````wiki
> Entering new AgentExecutor chain...
Thought: We can use the calculator tool to find 25% of 300.
Action:
```
{
  "action": "Calculator",
  "action_input": "25% of 300"
}
```
Observation: Answer: 75.0
Thought:Final Answer: 75.0

> Finished chain.
{'input': 'What is the 25% of 300?', 'output': '75.0'}
````

**agentæŸ¥è¯¢ç»´åŸºç™¾ç§‘**

```python
question = "Tom M. Mitchell is an American computer scientist \
and the Founders University Professor at Carnegie Mellon University (CMU)\
what book did he write?"
result = agent(question) 
```

````wiki
> Entering new AgentExecutor chain...
Thought: I can use Wikipedia to find out which book Tom M. Mitchell wrote.
Action:
```
{
  "action": "Wikipedia",
  "action_input": "Tom M. Mitchell"
}
```
Observation: Page: Tom M. Mitchell
Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past president of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.

Page: Ensemble learning
Summary: In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.
Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.


Thought:I have found that Tom M. Mitchell wrote the textbook "Machine Learning."

Final Answer: Tom M. Mitchell wrote the book "Machine Learning."

> Finished chain.
````

>å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œä»£ç†è§£å†³é—®é¢˜æœ‰ä¸€ä¸ªå›ºå®šçš„æµç¨‹ï¼š
>
>Thought
>
>Action
>
>Observation
>
>Thought
>
>Final Answer

### Python Agent

```python
# åˆ›å»ºpython agent
agent = create_python_agent(
    llm,
    tool=PythonREPLTool(),
    verbose=True
)
```

`create_python_agent`åˆ›å»ºèƒ½å¤Ÿè¿è¡Œpythonä»£ç çš„agentã€‚`tool`ä½¿ç”¨`PythonREPLTool()`å·¥å…·ï¼Œå…è®¸ä»£ç†æ‰§è¡Œä»»ä½•pythonä»£ç ï¼Œè¯¥å·¥å…·åˆ›å»ºäº†ä¸€ä¸ªä¸´æ—¶çš„Pythonè§£é‡Šå™¨ç¯å¢ƒã€‚

è®©agentå¯¹äººåè¿›è¡Œæ’åºï¼š

```python
customer_list = [["Harrison", "Chase"], 
                 ["Lang", "Chain"],
                 ["Dolly", "Too"],
                 ["Elle", "Elem"], 
                 ["Geoff","Fusion"], 
                 ["Trance","Former"],
                 ["Jen","Ayai"]
                ]

agent.run(f"""Sort these customers by \
last name and then first name \
and print the output: {customer_list}""") 
```

```wiki
> Entering new AgentExecutor chain...
We can use the sorted() function in Python to sort the list of customers based on last name first and then first name.
Action: Use the sorted() function
Action Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))
Observation: Use the sorted() function is not a valid tool, try another one.
Thought:We can use the sorted() function with a custom key function to sort the list of customers based on last name first and then first name.
Action: Use the sorted() function with a custom key function
Action Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))
Observation: Use the sorted() function with a custom key function is not a valid tool, try another one.
Thought:We can use the sorted() function with a lambda function to sort the list of customers based on last name first and then first name.
Action: Use the sorted() function with a lambda function
Action Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))
Observation: Use the sorted() function with a lambda function is not a valid tool, try another one.
Thought:We can use the sorted() function with a lambda function to sort the list of customers based on last name first and then first name.
Action: Use the sorted() function with a lambda function
Action Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))
Observation: Use the sorted() function with a lambda function is not a valid tool, try another one.
Thought:We can use the sorted() function with a lambda function to sort the list of customers based on last name first and then first name.
Action: Use the sorted() function with a lambda function
Action Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))
Observation: Use the sorted() function with a lambda function is not a valid tool, try another one.
Thought:We can use the sorted() function with a lambda function to sort the list of customers based on last name first and then first name.
Action: Use the sorted() function with a lambda function
Action Input: sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0]))
Observation: Use the sorted() function with a lambda function is not a valid tool, try another one.
Thought:I now know the final answer
Final Answer: [['Jen', 'Ayai'], ['Harrison', 'Chase'], ['Lang', 'Chain'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]
```

python agenté‡å¤å¤šæ¬¡æ‰§è¡Œï¼ˆ`Action`ã€`Action Input`ã€`Observation`ã€`Thought`ï¼‰æœ€ç»ˆå¾—åˆ°`Final Answer`ã€‚

### Define your own tool

agentè°ƒç”¨è‡ªå®šä¹‰å·¥å…·ã€‚è‡ªå®šä¹‰`time`å‡½æ•°è·å–å½“å‰æ—¥æœŸï¼Œå½“æˆ‘ä»¬è¯¢é—®å½“å‰æ—¥æœŸæ—¶ï¼Œagentä¼šè°ƒç”¨`time`å‡½æ•°ã€‚æ³¨æ„ï¼š`time`å‡½æ•°éœ€è¢«`@tool`è£…é¥°ã€‚

```python
from langchain.agents import tool
from datetime import date

@tool
def time(text: str) -> str:
    """Returns todays date, use this for any \
    questions related to knowing todays date. \
    The input should always be an empty string, \
    and this function will always return todays \
    date - any date mathmatics should occur \
    outside this function."""
    return str(date.today())

agent= initialize_agent(
    [time], 
    llm, 
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    handle_parsing_errors=True,
    verbose = True)
```

**è¯¢é—®ä»Šå¤©çš„æ—¥æœŸ**

```python
try:
    result = agent("whats the date today?") 
except: 
    print("exception on external access")
```

````wiki
> Entering new AgentExecutor chain...
Thought: I can use the `time` tool to find out today's date.
Action:
```
{
  "action": "time",
  "action_input": ""
}
```

Observation: 2024-12-11
Thought:Final Answer: 2024-12-11
````

## Conclusion

æœ¬è¯¾ç¨‹é¦–å…ˆä»‹ç»äº†LangChainçš„åŸºæœ¬æ¦‚å¿µå’ŒåŸºç¡€ç»„ä»¶ï¼ˆModels, Prompts, Parsers, Chainsï¼‰ï¼Œç„¶ååˆ©ç”¨è¿™äº›ç»„ä»¶æ­å»ºQ&Aç³»ç»Ÿå¹¶å¯¹å…¶è¿›è¡Œè¯„ä¼°ï¼Œæœ€åä»‹ç»äº†Agentçš„ç”¨æ³•ã€‚
