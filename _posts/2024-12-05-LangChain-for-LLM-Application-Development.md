---
title: LangChain for LLM Application Development
date: 2024-12-05 16:40:00 +/-8
categories: [LLM, Andrew Ng]
tags: [openai, software develop, langchain]     # TAG names should always be lowercase
---

æœ¬è¯¾ç¨‹æ˜¯å´æ©è¾¾ä¸OpenAIã€Hugging Faceã€LangChainç­‰æœºæ„è”åˆæ‰“é€ ï¼Œé¢å‘å¼€å‘è€…çš„LLMç³»åˆ—è¯¾ç¨‹ç¬¬ä¸‰è®²â€”â€”ç”¨äºLLMåº”ç”¨ç¨‹åºå¼€å‘çš„LangChainï¼Œç”±LangChainè”åˆåˆ›å§‹äººå…¼CEO Harrison Chaseå’Œå´æ©è¾¾åˆä½œæˆè¯¾ã€‚

## è¯¾ç¨‹é“¾æ¥

[LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)

>å»ºè®®å¤§å®¶ç›´æ¥çœ‹DeepLearning.AIä¸Šçš„è‹±æ–‡åŸç‰ˆï¼Œé…åˆå®˜æ–¹æä¾›çš„Jupyter Notebookæ•ˆæœæ›´ä½³ã€‚Bç«™ä¸Šçš„ç¿»è¯‘ç¨€çƒ‚ï¼Œä¸å»ºè®®çœ‹ï¼Œå¯èƒ½ä¼šé€ æˆè¯¯å¯¼ã€‚
>

## æ¦‚è¿°

åŸºäºLLM APIå¼€å‘åº”ç”¨ç¨‹åºï¼Œå¼€å‘è€…ä¸å¾—ä¸ç¼–å†™å¾ˆå¤šèƒ¶æ°´ä»£ç æ‰èƒ½æ­å»ºå®Œæ•´çš„ç¨‹åºæ¡†æ¶ã€‚LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘åŸºäºLLMçš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ï¼Œå®ƒç®€åŒ–äº†LLMåº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼ŒåŒ…æ‹¬å¼€å‘ã€éƒ¨ç½²å’Œäº§å“åŒ–ï¼Œå·²ç»è¢«å¹¿å¤§å¼€å‘è€…ã€åˆåˆ›å…¬å¸å’Œå¤§å‹ä¼ä¸šå¹¿æ³›ä½¿ç”¨ã€‚

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ å¹¶ä½¿ç”¨LangChainå¼€å‘å®Œæ•´å¥å£®çš„åº”ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š

- Models, Prompts and Parsersï¼šè°ƒç”¨LLMï¼Œæä¾›promptï¼Œè§£æresponseï¼›
- Memories for LLMsï¼šå­˜å‚¨å¯¹è¯å’Œç®¡ç†æœ‰é™ä¸Šä¸‹æ–‡ç©ºé—´ï¼›
- Chainsï¼šåˆ›å»ºæ“ä½œåºåˆ—ï¼›
- Question Answering over Documentsï¼šå°†LLMåº”ç”¨åˆ°ä¸“æœ‰æ•°æ®å’Œç”¨ä¾‹ï¼›
- Agentsï¼šæ¢ç´¢LLMä½œä¸ºæ¨ç†ä»£ç†çš„å¼ºå¤§æ–°å…´å‘å±•ã€‚

## Introduction

ä¸ºäº†ç®€åŒ–åŸºäºLLMçš„AIåº”ç”¨ç¨‹åºå¼€å‘ï¼ŒHarrison Chaseåˆ›é€ äº†LangChainã€‚LangChainæ˜¯å¼€å‘æ¡†æ¶ä¹Ÿæ˜¯æ´»è·ƒçš„å¼€æºç¤¾åŒºï¼Œæœ‰æ•°ç™¾åè´¡çŒ®è€…ï¼Œæ­£ä»¥æƒŠäººçš„é€Ÿåº¦è¿­ä»£æ–°åŠŸèƒ½ã€‚LangChainæä¾›Pythonå’ŒJavaScriptä¸¤ç§åŒ…ï¼Œä¸“æ³¨äºç»„åˆå’Œæ¨¡å—åŒ–ï¼Œå¯ä»¥è½»æ¾çš„å°†å„ä¸ªç»„ä»¶ç»“åˆèµ·æ¥åˆ›å»ºç«¯åˆ°ç«¯åº”ç”¨ç¨‹åºã€‚

æœ¬è¯¾ç¨‹é‡ç‚¹ä»‹ç»LangChainçš„å¸¸ç”¨ç»„ä»¶ï¼šModels, Prompts, Indexes, Chains, Agentsã€‚

![](../assets/images/llm_develop/langchain-1.png)

## Models, Prompts and Parsers

### Chat API : LangChain

å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„`langchain`åŒ…

```python
pip install --upgrade langchain
```

### Model

ä»`langchain.chat_models`å¯¼å…¥OpenAIå¯¹è¯æ¨¡å‹ã€‚LangChainä¹Ÿé›†æˆäº†å…¶ä»–å‚å•†çš„æ¨¡å‹ï¼Œå¦‚Anthropicã€Googleç­‰ï¼Œå‚è§[Providers | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/integrations/providers/)

```python
from langchain.chat_models import ChatOpenAI
```

å£°æ˜ä¸€ä¸ªmodel

```python
chat = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')
```

### Prompt template

ä½¿ç”¨LangChainæ„é€ promptæ¨¡æ¿ï¼Œå°†éœ€è¦æ”¹åŠ¨çš„éƒ¨åˆ†æŠ½è±¡æˆå˜é‡ï¼Œå…·ä½“ä½¿ç”¨æ—¶æŠ½è±¡æˆæ‰€éœ€è¦çš„å†…å®¹ã€‚è¾¾åˆ°ä¸€æ¬¡å®šä¹‰ï¼Œå¤šæ¬¡ä½¿ç”¨çš„æ•ˆæœã€‚

**é¦–å…ˆå®šä¹‰æ¨¡æ¿å­—ç¬¦ä¸²ï¼š**

```python
template_string = """Translate the text \
that is delimited by triple backticks \
into a style that is {style}. \
text: ```{text}```
"""
```

ä»`langchain.prompts`å¯¼å…¥`ChatPromptTemplate`ç”¨æ¥å®ä¾‹åŒ–promptæ¨¡æ¿ã€‚

```python
from langchain.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_template(template_string)
```

è¾“å‡º`prompt_template`å¯ä»¥å‘ç°ï¼Œ`input_variables`å°±æ˜¯`template_string`ä¸­å®šä¹‰çš„`{text}`å’Œ`{style}`ã€‚åç»­ä½¿ç”¨ä¸­ï¼Œæ›¿æ¢`{text}`å’Œ`{style}`å¯æ–¹ä¾¿åœ°æ„é€ ä¸åŒçš„promptã€‚

![](../assets/images/llm_develop/langchain-2.png)

æˆ‘ä»¬ä½¿ç”¨`prompt_template`æ„é€ coustomer promptï¼Œå¹¶ä½¿ç”¨`chat`è°ƒç”¨'gpt-3.5-turbo'è·å¾—responseã€‚

**å®šä¹‰styleå’Œtext**

```python
# style
customer_style = """American English \
in a calm and respectful tone
"""

# text
customer_email = """
Arrr, I be fuming that me blender lid \
flew off and splattered me kitchen walls \
with smoothie! And to make matters worse, \
the warranty don't cover the cost of \
cleaning up me kitchen. I need yer help \
right now, matey!
"""
```

**æ„é€ customer prompt**

```python
customer_messages = prompt_template.format_messages(
                    style=customer_style,
                    text=customer_email)
```

**è°ƒç”¨'gpt-3.5-turbo'å°†`customer_email`è½¬æ¢ä¸º`customer_style`é£æ ¼**

```
customer_response = chat(customer_messages)
```

![](../assets/images/llm_develop/langchain-3.png)

### Parse the LLM output string into a Python dictionary

Parseræ˜¯LangChainèƒ½å¤Ÿæˆé“¾çš„å…³é”®ã€‚å› ä¸ºå®ƒä¼šå°†LLMçš„è¾“å‡ºè§£ææˆä½ æ‰€éœ€è¦çš„æ ¼å¼ï¼Œä¾‹å¦‚å­—å…¸ã€‚å°†æ­¤è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ¨¡å—çš„è¾“å…¥ï¼Œä»è€Œå¯ä»¥å°†ä¸¤ä¸ªæ¨¡å—å…³è”èµ·æ¥ã€‚

**å¯¼å…¥å¿…è¦çš„åº“ï¼š**

ä»`langchain`åº“çš„`output_parsers`æ¨¡å—ä¸­å¯¼å…¥`ResponseSchema`å’Œ`StructuredOutputParser`

- `ResponseSchema`ç”¨äºå®šä¹‰å’ŒéªŒè¯è¾“å‡ºçš„é¢„æœŸç»“æ„ï¼›

- `StructuredOutputParser`ç”¨äºå°†è¾“å‡ºè§£æä¸ºç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºåç»­å¤„ç†å’Œåˆ†æã€‚

```python
from langchain.output_parsers import ResponseSchema
from langchain.output_parsers import StructuredOutputParser
```

**ç”Ÿæˆå¯¹åº”æ ¼å¼çš„Schemaï¼š**

å‡è®¾LLMçš„è¾“å‡ºæ ¼å¼æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œæœ‰ä¸‰ä¸ªkeyåˆ†åˆ«ä¸ºgiftã€delivery_daysã€å’Œprice_valueã€‚

```python
{
  "gift": False,
  "delivery_days": 5,
  "price_value": "pretty affordable!"
}
```

ä½¿ç”¨`ResponseSchema`ç”ŸæˆSchemaï¼š

```python
gift_schema = ResponseSchema(name="gift",
                             description="Was the item purchased\
                             as a gift for someone else? \
                             Answer True if yes,\
                             False if not or unknown.")
delivery_days_schema = ResponseSchema(name="delivery_days",
                                      description="How many days\
                                      did it take for the product\
                                      to arrive? If this \
                                      information is not found,\
                                      output -1.")
price_value_schema = ResponseSchema(name="price_value",
                                    description="Extract any\
                                    sentences about the value or \
                                    price, and output them as a \
                                    comma separated Python list.")

response_schemas = [gift_schema, 
                    delivery_days_schema,
                    price_value_schema]
```

**ç”Ÿæˆè§£æLLM responseçš„parserï¼š**

```python
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
```

**è·å–è¾“å‡ºæ ¼å¼è¯´æ˜ï¼š**

```python
format_instructions = output_parser.get_format_instructions()
```

![](../assets/images/llm_develop/langchain-4.png)

**ç”Ÿæˆpromptï¼š**

å®šä¹‰promptæ¨¡æ¿ï¼Œç”ŸæˆåŒ…å«æ–‡æœ¬å’Œformat_instructionsçš„promptã€‚

```python
review_template_2 = """\
For the following text, extract the following information:

gift: Was the item purchased as a gift for someone else? \
Answer True if yes, False if not or unknown.

delivery_days: How many days did it take for the product\
to arrive? If this information is not found, output -1.

price_value: Extract any sentences about the value or price,\
and output them as a comma separated Python list.

text: {text}

{format_instructions}
"""

prompt = ChatPromptTemplate.from_template(template=review_template_2)

messages = prompt.format_messages(text=customer_review, 
                                format_instructions=format_instructions)
```

**è°ƒç”¨LLMç”Ÿæˆresponse**

```python
response = chat(messages)
```

`response.content`ä¸º`str`æ ¼å¼

![](../assets/images/llm_develop/langchain-6.png)

**parserè§£æä¸ºdictæ ¼å¼**

```python
output_dict = output_parser.parse(response.content)
```

![](../assets/images/llm_develop/langchain-7.png)

## Memory

è¯­è¨€æ¨¡å‹æ˜¯æ— çŠ¶æ€çš„ï¼Œç”¨æˆ·æ¯ä¸€æ¬¡ä¸è¯­è¨€æ¨¡å‹çš„äº¤äº’éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæ¢å¥è¯è¯´ï¼Œè¯­è¨€æ¨¡å‹å¹¶ä¸è®°å¾—åˆ°ç›®å‰ä¸ºæ­¢çš„å†å²å¯¹è¯ã€‚å› æ­¤ï¼Œåœ¨æ„å»ºåº”ç”¨ç¨‹åºæ—¶ï¼Œå¯¹è¯ç¼ºä¹çœŸæ­£çš„è¿ç»­æ€§ã€‚LangChainçš„Memoryæ¨¡å—å¯ä»¥å°†å…ˆå‰çš„å¯¹è¯åµŒå…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­ï¼Œä½¿å¯¹è¯å…·æœ‰è¿ç»­æ€§ã€‚

LangChainå…·æœ‰å¤šç§Memoryï¼Œæœ¬è¯¾ç¨‹ä¸»è¦ä»‹ç»å…¶ä¸­å››ç§ï¼š

- **ConversationBufferMemory**
- **ConversationBufferWindowMemory**
- **ConversationTokenBufferMemory**
- **ConversationSummaryMemory**

æ›´å¤šMemoryè¯·å‚è€ƒAPIæ‰‹å†Œï¼š[memory](https://api.python.langchain.com/en/latest/langchain/memory.html)

### ConversationBufferMemory

**å¯¼å…¥Model, Chainå’ŒMemory**

```python
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
```

**æ„å»ºConversation**

```python
llm = ChatOpenAI(temperature=0.0, model=llm_model)
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=llm, 
    memory = memory,
    verbose=True
)
```

**è°ƒç”¨`.predict()`å¯åŠ¨å¯¹è¯**

```python
conversation.predict(input="Hi, my name is Andrew")
conversation.predict(input="What is 1+1?")
conversation.predict(input="What is my name?")
```

æˆ‘ä»¬è¿ç»­è¿›è¡Œä¸‰è½®å¯¹è¯ï¼Œçœ‹çœ‹æ¨¡å‹å†…éƒ¨åˆ°åº•å­˜å‚¨äº†äº›ä»€ä¹ˆã€‚

![](../assets/images/llm_develop/langchain-8.png)

æ¨¡å‹å­˜å‚¨äº†å†å²å¯¹è¯çš„æ‰€æœ‰å†…å®¹ï¼Œå› æ­¤å®ƒçŸ¥é“ç”¨æˆ·çš„åå­—æ˜¯Andrewã€‚

è¯¦æƒ…è¯·çœ‹ï¼š[ConversationBufferMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html#langchain.memory.buffer.ConversationBufferMemory)

### ConversationBufferWindowMemory

[ConversationBufferWindowMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html)åªä¿ç•™æœ€è¿‘çš„ä¸€ä¸ªçª—å£å¤§å°çš„å¯¹è¯ã€‚

å£°æ˜`k=1`çš„`ConversationBufferWindowMemory`

```python
from langchain.memory import ConversationBufferWindowMemory

llm = ChatOpenAI(temperature=0.0, model=llm_model)
memory = ConversationBufferWindowMemory(k=1)
conversation = ConversationChain(
    llm=llm, 
    memory = memory,
    verbose=False
)
```

è¿ç»­è¿›è¡Œä¸‰è½®å¯¹è¯

```python
conversation.predict(input="Hi, my name is Andrew")
conversation.predict(input="What is 1+1?")
conversation.predict(input="What is my name?")
```

![](../assets/images/llm_develop/langchain-9.png)

æˆ‘ä»¬è®¾ç½®çª—å£çš„å¤§å°ä¸º`k=1`ï¼Œæ¨¡å‹åªå­˜å‚¨æœ€è¿‘çš„ä¸€è½®å¯¹è¯ï¼Œæ‰€ä»¥æ¨¡å‹å¹¶ä¸çŸ¥é“ç”¨æˆ·çš„åå­—ï¼Œè™½ç„¶ç”¨æˆ·å·²ç»å‘Šè¯‰è¿‡å®ƒï¼Œä½†æ¨¡å‹å¹¶æ²¡æœ‰å­˜å‚¨ã€‚

### ConversationTokenBufferMemory

[ConversationTokenBufferMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.token_buffer.ConversationTokenBufferMemory.html)ä»tokenæ•°é‡ä¸Šé™åˆ¶Memoryçš„å¤§å°ï¼Œå­˜å‚¨æœ€è¿‘çš„`max_token_limit`ä¸ªtokenã€‚

```python
from langchain.memory import ConversationTokenBufferMemory

memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)
```

### ConversationSummaryMemory

[ConversationSummaryMemory](https://api.python.langchain.com/en/latest/langchain/memory/langchain.memory.summary.ConversationSummaryMemory.html)å­˜å‚¨æœ€è¿‘å†å²å¯¹è¯çš„æ‘˜è¦ï¼Œè€Œä¸æ˜¯åŸå§‹å¯¹è¯ã€‚åŒæ ·ï¼Œæ‘˜è¦ä¸èƒ½è¶…è¿‡`max_token_limit`ä¸ªtokenã€‚

```python
from langchain.memory import ConversationSummaryBufferMemory

memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)
```

## Chains

[é“¾ï¼ˆchainï¼‰](https://python.langchain.com/api_reference/langchain/chains.html)æ˜¯LangChainä¸­æœ€é‡è¦çš„ç»„ä»¶ï¼Œå°†LLMå’Œpromptç»“åˆåœ¨ä¸€èµ·ã€‚æˆ‘ä»¬å¯ä»¥å°†å¤šä¸ªé“¾è¿æ¥åœ¨ä¸€èµ·ï¼Œåœ¨æ–‡æœ¬æˆ–è€…æ•°æ®ä¸Šè¿›è¡Œä¸€ç³»åˆ—çš„æ“ä½œã€‚

### LLMChain

[LLMChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain)æ˜¯ç®€å•è€Œå¼ºå¤§çš„é“¾ï¼Œæ˜¯å…¶ä»–å¤æ‚é“¾çš„åŸºç¡€ã€‚

**å¯¼å…¥llm, prompt template, chain**

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
```

**åˆ›å»ºllmå’Œprompt template**

```python
llm = ChatOpenAI(temperature=0.9, model=llm_model)

prompt = ChatPromptTemplate.from_template(
    "What is the best name to describe \
    a company that makes {product}?"
)
```

**åˆ›å»ºä¸€ä¸ªLLMChainå®ä¾‹ï¼Œå®ƒå°†ä¸€ä¸ªllmå’Œä¸€ä¸ªprompt templateç»“åˆèµ·æ¥**

```python
chain = LLMChain(llm=llm, prompt=prompt)
```

**è°ƒç”¨LLMChainå®ä¾‹çš„runæ–¹æ³•ï¼Œå°†productä½œä¸ºè¾“å…¥ä¼ é€’ç»™é“¾ï¼Œå¹¶æ‰§è¡Œé“¾ä¸­å®šä¹‰çš„æµç¨‹**

```
product = "Queen Size Sheet Set"
chain.run(product)
```

### SimpleSequentialChain

[SimpleSequentialChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sequential.SimpleSequentialChain.html#langchain.chains.sequential.SimpleSequentialChain)æ˜¯é¡ºåºé“¾æœ€ç®€å•çš„å½¢å¼ï¼Œå…¶ä¸­æ¯ä¸ªæ­¥éª¤éƒ½æœ‰ä¸€ä¸ªå•ä¸€çš„è¾“å…¥/è¾“å‡ºï¼Œå¹¶ä¸”ä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºæ˜¯ä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ã€‚

**å¯¼å…¥SimpleSequentialChain**

```python
from langchain.chains import SimpleSequentialChain
```

**åˆ›å»ºä¸¤ä¸ªLLMChainå®ä¾‹ä½œä¸ºå­é“¾**

```py
llm = ChatOpenAI(temperature=0.9, model=llm_model)

# prompt template 1
first_prompt = ChatPromptTemplate.from_template(
    "What is the best name to describe \
    a company that makes {product}?"
)

# Chain 1
chain_one = LLMChain(llm=llm, prompt=first_prompt)
```

```python
# prompt template 2
second_prompt = ChatPromptTemplate.from_template(
    "Write a 20 words description for the following \
    company:{company_name}"
)
# chain 2
chain_two = LLMChain(llm=llm, prompt=second_prompt)
```

**ä½¿ç”¨SimpleSequentialChainå°†ä¸¤ä¸ªå­é“¾ç»„è£…èµ·æ¥**

```
overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],
                                             verbose=True
                                            )
```

**è°ƒç”¨runæ–¹æ³•æ‰§è¡Œæµç¨‹**

```python
overall_simple_chain.run(product)
```

### SequentialChain

[SequentialChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sequential.SequentialChain.html#langchain.chains.sequential.SequentialChain)æ˜¯æ›´é€šç”¨çš„é¡ºåºé“¾å½¢å¼ï¼Œå…è®¸å¤šä¸ªè¾“å…¥å’Œè¾“å‡ºã€‚

**å¯¼å…¥SequentialChain**

```python
from langchain.chains import SequentialChain
```

**åˆ›å»ºå››ä¸ªLLMChainå®ä¾‹ä½œä¸ºå­é“¾**

```python
llm = ChatOpenAI(temperature=0.9, model=llm_model)

# prompt template 1: translate to english
first_prompt = ChatPromptTemplate.from_template(
    "Translate the following review to english:"
    "\n\n{Review}"
)
# chain 1: input= Review and output= English_Review
chain_one = LLMChain(llm=llm, prompt=first_prompt, 
                     output_key="English_Review"
                    )
```

```python
second_prompt = ChatPromptTemplate.from_template(
    "Can you summarize the following review in 1 sentence:"
    "\n\n{English_Review}"
)
# chain 2: input= English_Review and output= summary
chain_two = LLMChain(llm=llm, prompt=second_prompt, 
                     output_key="summary"
                    )
```

```python
# prompt template 3: translate to english
third_prompt = ChatPromptTemplate.from_template(
    "What language is the following review:\n\n{Review}"
)
# chain 3: input= Review and output= language
chain_three = LLMChain(llm=llm, prompt=third_prompt,
                       output_key="language"
                      )
```

```python
# prompt template 4: follow up message
fourth_prompt = ChatPromptTemplate.from_template(
    "Write a follow up response to the following "
    "summary in the specified language:"
    "\n\nSummary: {summary}\n\nLanguage: {language}"
)
# chain 4: input= summary, language and output= followup_message
chain_four = LLMChain(llm=llm, prompt=fourth_prompt,
                      output_key="followup_message"
                     )
```

æ¯ä¸ªå­é“¾éƒ½æŒ‡å®šäº†`output_key`æ ‡è¯†å­é“¾çš„è¾“å‡ºï¼Œæ¯ä¸ªpromptä¸­çš„å ä½ç¬¦{xxx}è¡¨ç¤ºè¯¥å­é“¾çš„è¾“å…¥ã€‚è¾“å…¥è¾“å‡º

å˜é‡çš„åç§°è¦ä¸¥æ ¼å¯¹åº”ï¼Œå¦åˆ™ä¼šå‡ºç°key errorã€‚

**åˆ›å»ºSequentialChain**

```python
# overall_chain: input= Review 
# and output= English_Review,summary, followup_message
overall_chain = SequentialChain(
    chains=[chain_one, chain_two, chain_three, chain_four],
    input_variables=["Review"],
    output_variables=["English_Review", "summary","language","followup_message"],
    verbose=True
)
```

- **chains**ï¼šé¡ºåºé“¾ä¸­åŒ…å«çš„å­é“¾åˆ—è¡¨ï¼›
- **input_variables**ï¼šè¾“å…¥å˜é‡åˆ—è¡¨ï¼Œç”±äºç¬¬ä¸€ä¸ªå­é“¾çš„è¾“å…¥æ˜¯`{Review}`ï¼Œå› æ­¤è¾“å…¥å˜é‡ä¸º`["Review"]`;
- **output_variables**ï¼šè¾“å‡ºå˜é‡åˆ—è¡¨ã€‚

**æ‰§è¡Œé¡ºåºé“¾**

```python
review = df.Review[5]
overall_chain(review)
```

![](../assets/images/llm_develop/langchain-10.png)

è¾“å‡º`output_variables`ä¸­æŒ‡å®šçš„å˜é‡`["English_Review", "summary","language","followup_message"]`ã€‚

### Router Chain

Router Chainï¼ˆè·¯ç”±é“¾ï¼‰å…è®¸æ ¹æ®è¾“å…¥çš„promptä»ç»™å®šçš„ä¸€ç»„é“¾ä¸­åŠ¨æ€é€‰æ‹©ä¸€ä¸ªé¢„å®šä¹‰çš„å­é“¾ã€‚

**å®šä¹‰ä¸€ç»„prompt template**

```python
physics_template = """You are a very smart physics professor. \
You are great at answering questions about physics in a concise\
and easy to understand manner. \
When you don't know the answer to a question you admit\
that you don't know.

Here is a question:
{input}"""


math_template = """You are a very good mathematician. \
You are great at answering math questions. \
You are so good because you are able to break down \
hard problems into their component parts, 
answer the component parts, and then put them together\
to answer the broader question.

Here is a question:
{input}"""

history_template = """You are a very good historian. \
You have an excellent knowledge of and understanding of people,\
events and contexts from a range of historical periods. \
You have the ability to think, reflect, debate, discuss and \
evaluate the past. You have a respect for historical evidence\
and the ability to make use of it to support your explanations \
and judgements.

Here is a question:
{input}"""


computerscience_template = """ You are a successful computer scientist.\
You have a passion for creativity, collaboration,\
forward-thinking, confidence, strong problem-solving capabilities,\
understanding of theories and algorithms, and excellent communication \
skills. You are great at answering coding questions. \
You are so good because you know how to solve a problem by \
describing the solution in imperative steps \
that a machine can easily interpret and you know how to \
choose a solution that has a good balance between \
time complexity and space complexity. 

Here is a question:
{input}"""
```

**å¯¹æ¯ä¸ªtemplateè¿›è¡Œå‘½åå’Œæè¿°ï¼Œå°è£…æˆå­—å…¸**

```python
prompt_infos = [
    {
        "name": "physics", 
        "description": "Good for answering questions about physics", 
        "prompt_template": physics_template
    },
    {
        "name": "math", 
        "description": "Good for answering math questions", 
        "prompt_template": math_template
    },
    {
        "name": "History", 
        "description": "Good for answering history questions", 
        "prompt_template": history_template
    },
    {
        "name": "computer science", 
        "description": "Good for answering computer science questions", 
        "prompt_template": computerscience_template
    }
]
```

**å¯¼å…¥MultiPromptChainï¼Œ LLMRouterChainï¼ŒRouterOutputParserï¼ŒPromptTemplate**

```python
from langchain.chains.router import MultiPromptChain
from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser
from langchain.prompts import PromptTemplate
```

**ä¸º`prompt_infos`ä¸­æ¯ä¸ªpromptåˆ›å»ºå­é“¾ï¼Œå¹¶åŠ å…¥`destination_chains`**

```python
destination_chains = {}
for p_info in prompt_infos:
    name = p_info["name"]
    prompt_template = p_info["prompt_template"]
    prompt = ChatPromptTemplate.from_template(template=prompt_template)
    chain = LLMChain(llm=llm, prompt=prompt)
    destination_chains[name] = chain  
    
destinations = [f"{p['name']}: {p['description']}" for p in prompt_infos]
destinations_str = "\n".join(destinations)
```

**åˆ›å»ºé»˜è®¤é“¾ï¼Œå½“æ— æ³•å†³å®šè°ƒç”¨å“ªä¸€æ¡å­é“¾æ—¶ï¼Œè°ƒç”¨é»˜è®¤é“¾**

```python
default_prompt = ChatPromptTemplate.from_template("{input}")
default_chain = LLMChain(llm=llm, prompt=default_prompt)
```

**æ„å»ºè·¯ç”±é“¾**

```
router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(
    destinations=destinations_str
)
router_prompt = PromptTemplate(
    template=router_template,
    input_variables=["input"],
    output_parser=RouterOutputParser(),
)

router_chain = LLMRouterChain.from_llm(llm, router_prompt)
```

`LLMRouterChain`æ ¹æ®è¾“å…¥åŠ¨æ€åœ°å°†ä»»åŠ¡è·¯ç”±åˆ°é€‚å½“çš„å­é“¾ï¼Œå³ä¸åŒçš„`LLMChain`ã€‚

**å°è£…æ€»ä½“é“¾è·¯**

```python
chain = MultiPromptChain(router_chain=router_chain, 
                         destination_chains=destination_chains, 
                         default_chain=default_chain, verbose=True
                        )
```

`MultiPromptChain`å…è®¸æ ¹æ®ä¸åŒçš„è¾“å…¥å†…å®¹ï¼ŒåŠ¨æ€é€‰æ‹©ä¸åŒçš„é“¾è·¯ã€‚

**æµ‹è¯•è·¯ç”±é“¾**

```python
chain.run("What is black body radiation?") # æé—®ç‰©ç†é—®é¢˜
```

```wiki
# è¢«è·¯ç”±åˆ°ç‰©ç†é“¾è·¯
> Entering new MultiPromptChain chain...
physics: {'input': 'What is black body radiation?'}
> Finished chain.
"Black body radiation is the type of electromagnetic radiation that is emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation, regardless of frequency or angle of incidence. The radiation has a specific spectrum and intensity that depends only on the body's temperature, which is assumed to be uniform and constant. This phenomenon was first explained by Max Planck in 1900, and it is a foundational concept in quantum mechanics."
```

```python
chain.run("Why does every cell in our body contain DNA?") # æé—®ç”Ÿç‰©é—®é¢˜
```

```wiki
# ç”±äºæ²¡æœ‰â€œç”Ÿç‰©â€ç±»çš„prompt templateï¼Œå› æ­¤è¢«è·¯ç”±åˆ°é»˜è®¤é“¾è·¯ã€‚
> Entering new MultiPromptChain chain...
None: {'input': 'Why does every cell in our body contain DNA?'}
> Finished chain.
'DNA, or deoxyribonucleic acid, is the hereditary material in humans and almost all other organisms. It contains the instructions needed for an organism to develop, survive and reproduce. These instructions are found inside every cell, and are passed down from parents to their children.\n\nDNA is organized into structures called chromosomes and is divided into segments known as genes. Each gene contains a specific set of instructions that code for particular proteins that perform various functions in the body.\n\nTherefore, every cell in our body contains DNA because it is essential for life. It provides the instructions for the growth, development, function and reproduction of cells. Without DNA, our cells would not know what to do or how to function, and life as we know it would not exist.'
```

## Question and Answer

ä½¿ç”¨LLMæ„å»ºåŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿæ˜¯ç›®å‰æœ€å¸¸è§çš„åœºæ™¯ä¹‹ä¸€ã€‚ç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œä½¿ç”¨LLMå›ç­”ç”¨æˆ·æœ‰å…³è¯¥æ–‡æœ¬çš„é—®é¢˜ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·å¯¹æ–‡æœ¬æœ‰æ›´æ·±çš„ç†è§£æˆ–è€…æå–ç”¨æˆ·å…³å¿ƒçš„å†…å®¹ã€‚è¯¥åœºæ™¯å°†LLMä¸å¤–éƒ¨æ•°æ®ç»“åˆèµ·æ¥ï¼Œæé«˜LLMä½¿ç”¨çš„çµæ´»æ€§å¹¶æ‰©å¤§äº†é€‚ç”¨èŒƒå›´ã€‚

### LangChain: Q&A over Documents

ä½¿ç”¨LangChainç´¢å¼•æ­å»ºåŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿã€‚

**åˆ›å»ºæ–‡æ¡£åŠ è½½å™¨**

ä»`.csv`æ–‡æ¡£ä¸­è¯»å–æ•°æ®ï¼Œåˆ›å»º`CSVLoader`

```python
file = 'OutdoorClothingCatalog_1000.csv'
loader = CSVLoader(file_path=file)
```

**åˆ›å»ºç´¢å¼•**

åˆ›å»ºäº†æ–‡æ¡£åŠ è½½å™¨loderä¹‹åï¼Œè¿˜éœ€è¦åˆ›å»ºç”¨äºæ£€ç´¢æ–‡æ¡£å†…å®¹çš„ç´¢å¼•`index`ã€‚

`VectorstoreIndexCreator`ç”¨äºåˆ›å»ºå’Œç®¡ç†å‘é‡å­˜å‚¨ç´¢å¼•ï¼Œä¾¿äºå¯¹å¤§é‡æ–‡æ¡£è¿›è¡Œé«˜æ•ˆæ£€ç´¢ã€‚å®ƒé€šè¿‡ä¸å‘é‡æ•°æ®åº“é›†æˆï¼Œå¸®åŠ©ç”¨æˆ·æ„å»ºä¸€ä¸ªå¯æŸ¥è¯¢çš„ç´¢å¼•ã€‚æˆ‘ä»¬ä½¿ç”¨çš„å‘é‡æ•°æ®åº“æ˜¯`DocArrayInMemorySearch`ï¼Œå®ƒåŸºäº DocArray çš„å†…å­˜å­˜å‚¨åŠŸèƒ½ï¼Œå°†æ•´ä¸ªæ–‡æ¡£ä»¥å‘é‡çš„å½¢å¼å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œç”¨äºåœ¨æœ¬åœ°å†…å­˜ä¸­å­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡ï¼Œé€‚åˆå°è§„æ¨¡æˆ–åŸå‹åŒ–çš„è¯­ä¹‰æœç´¢ä»»åŠ¡ã€‚æœ€åè°ƒç”¨`.from_loaders`æ–¹æ³•ä»`loader`åˆ›å»ºç´¢å¼•ã€‚

```python
from langchain.indexes import VectorstoreIndexCreator

index = VectorstoreIndexCreator(
    vectorstore_cls=DocArrayInMemorySearch
).from_loaders([loader])
```

æ¥ä¸‹æ¥ç›´æ¥ä½¿ç”¨ç´¢å¼•å¯¹æ–‡æ¡£è¿›è¡Œé—®ç­”ï¼š

```python
query ="Please list all your shirts with sun protection \
in a table in markdown and summarize each one."

llm_replacement_model = OpenAI(temperature=0, 
                               model='gpt-3.5-turbo-instruct')

response = index.query(query, 
                       llm = llm_replacement_model)
                       
display(Markdown(response))
```

![](../assets/images/llm_develop/langchain-11.png)

llmè¿”å›4ä»¶å…·æœ‰é˜²æ™’åŠŸèƒ½çš„è¡¬è¡«ï¼Œå¹¶ä¸”å¯¹æ¯ä¸€ä»¶è¡¬è¡«éƒ½è¿›è¡Œäº†æ€»ç»“ï¼Œæœ€åä»¥markdownè¡¨æ ¼æ ¼å¼è¾“å‡ºï¼Œæ»¡è¶³`query`è¦æ±‚ã€‚

### Step By Step

ä½¿ç”¨`index.query()`æ–¹æ³•åªç”¨ä¸€è¡Œä»£ç å°±å¯ä»¥å®ç°æ–‡æ¡£é—®ç­”åŠŸèƒ½ï¼Œæœ¬èŠ‚æˆ‘ä»¬ä¸€èµ·æ¥æ¢ç´¢å…¶èƒŒåçš„åŸç†ã€‚

LLMä¸€æ¬¡åªèƒ½å¤„ç†å‡ åƒä¸ªå•è¯ï¼Œå½“é‡åˆ°è¾ƒå¤§è§„æ¨¡çš„æ–‡æ¡£æ—¶ï¼Œå¦‚ä½•ä½¿LLMå›ç­”å…³äºè¯¥æ–‡æ¡£çš„æ‰€æœ‰é—®é¢˜ï¼Ÿè¿™å°±éœ€è¦â€™embeddingsâ€˜å’Œâ€˜vector databaseâ€™ï¼Œæˆ‘ä»¬å…ˆä»‹ç»â€™embeddingsâ€˜å’Œâ€˜vector databaseâ€™çš„æ¦‚å¿µï¼Œç„¶åå†åˆ›å»ºæ–‡æ¡£é—®ç­”ç³»ç»Ÿstep by stepã€‚

#### Embeddings

Embeddingæ˜¯æŒ‡å°†è¯æ±‡ã€çŸ­è¯­ã€æ–‡æ¡£æˆ–å…¶ä»–ç±»å‹çš„æ•°æ®è½¬æ¢ä¸ºå®æ•°å‘é‡çš„è¿‡ç¨‹ã€‚ç›¸ä¼¼çš„è¯æˆ–æ¦‚å¿µåœ¨å‘é‡ç©ºé—´ä¸­å½¼æ­¤æ¥è¿‘ã€‚

![](../assets/images/llm_develop/embeddings.png)

å›¾ä¸­å¥å­1ï¼‰2ï¼‰éƒ½æ˜¯å…³äºåŠ¨ç‰©çš„ï¼Œå®ƒä»¬å…·æœ‰ç›¸ä¼¼çš„è¯­ä¹‰ï¼Œembeddingå‘é‡åœ¨ç©ºé—´ä¸­çš„ä½ç½®æ¯”è¾ƒæ¥è¿‘ã€‚å¥å­3ï¼‰æ˜¯å…³äºæ±½è½¦çš„ï¼Œembeddingå‘é‡ä¸å‰ä¸¤å¥è¯è·ç¦»è¾ƒè¿œã€‚

### Vector Database

åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æŠŠ`.csv`æ–‡æ¡£å­˜å…¥å†…å­˜è¿›è¡Œæ£€ç´¢ã€‚å¯¹äºå¤§è§„æ¨¡æ–‡æ¡£ï¼Œå†…å­˜æ˜¯è¿œè¿œä¸å¤Ÿçš„ï¼Œè¿™æ—¶å€™å°±è¦ç”¨åˆ°Vector Databaseï¼ˆå‘é‡æ•°æ®åº“ï¼‰ã€‚

![](../assets/images/llm_develop/vector_database_1.png)

**æ–‡æ¡£æ˜¯å¦‚ä½•å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“çš„ï¼Ÿ**

æ–‡æ¡£é¦–å…ˆè¢«åˆ’åˆ†ä¸ºå¾ˆå¤šchunkï¼ˆå—ï¼‰ï¼Œç„¶åå¯¹æ¯ä¸ªchunkä½œembeddingï¼Œæœ€åå°†embeddingå‘é‡å’ŒåŸæœ¬çš„chunkä¸€å¹¶å­˜å…¥æ•°æ®åº“ã€‚

### å‘æ–‡æ¡£æé—®

ç³»ç»Ÿå°†ç”¨æˆ·queryè½¬åŒ–ä¸ºembeddingå‘é‡ï¼Œå°†è¯¥å‘é‡ä¸å‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰å‘é‡è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºå‰nä¸ªæœ€ç›¸ä¼¼çš„å‘é‡ï¼Œå°†å…¶åŸå§‹chunkç»„åˆèµ·æ¥å–‚ç»™LLMç”Ÿæˆç­”æ¡ˆã€‚

![](../assets/images/llm_develop/vector_database_2.png)

